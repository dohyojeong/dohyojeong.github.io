[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Education\n\nPh.D. in Public Policy and Political Economy\nUniversity of Texas at Dallas, USA (Aug. 2020 - )\n\n\nMaster of Science in Social Data Analytics and Research\nUniversity of Texas at Dallas, USA (Aug. 2022 - )\n\n\nMaster of Public Administration\nSungkyunkwan University, Seoul, Korea (Mar. 2017 - Feb. 2019)\nThesis Title: Factor Affecting the Distribution of National Subsidies in Korean Local Governments: Focusing on Rhodes’ Power-Dependence Model (Advisor: Professor SUHO BAE)\n\n\nBachelor of Art in Philosophy & Public Administration (double major)\nSeokyeong University, Seoul, Korea (Mar. 2011 - Feb. 2017)\n\n\n\n\n\n\nAwards, Scholarships and Honors\n\nAwards 3rd prize in the treatise contest by the KOREA INSTITUTE OF PUBLIC FINANCE (Sep. 2022)\nAwards for Excellent Records, Sungkyunkwan University (Feb. 2019)\nAwards The 3rd Report for Korea National Tax Administration Policy Proposal Contest, National Tax Service (Nov. 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Fall 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Spring 2018)\nAcademic Excellence Scholarship, SUNGKYUNWAN UNIVERSITY (Fall 2017)\nAn Excellent-grade Scholarship, SEOKYEONG UNIVERSITY (Fall 2016)\nAn Excellent-grade Scholarship, SEOKYEONG UNIVERSITY (Spring 2016)"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Assignment1",
    "section": "",
    "text": "Q1: Google “generative art”. Cite some examples.\nExanple Link here.\nAt this link, you can check out ‘Generative Art: 50 Best Examples, Tools & Artists’ (2021 GUIDE).\n\n\n\n\nQ2: Run Fall.R\nI changed the color to ‘deeppink4’, and attached the output.\n\nBelow are the code and output.\n\n# Title Fall color\n# Credit: https://fronkonstin.com\n\n# Install packages\n\n#install.packages(\"gsubfn\")\n#install.packages(\"tidyverse\")\nlibrary(gsubfn)\n\nWarning: package 'gsubfn' was built under R version 4.0.5\n\n\nLoading required package: proto\n\n\nWarning: package 'proto' was built under R version 4.0.5\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'hms'\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.6     v purrr   0.3.4\nv tibble  3.1.4     v dplyr   1.0.7\nv tidyr   1.1.3     v stringr 1.4.0\nv readr   1.4.0     v forcats 0.5.1\n\n\nWarning: package 'tibble' was built under R version 4.0.5\n\n\nWarning: package 'tidyr' was built under R version 4.0.5\n\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: package 'stringr' was built under R version 4.0.5\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(ggplot2)\n\n# Define elements in plant art\n# Each image corresponds to a different axiom, rules, angle and depth\n\n# Leaf of Fall\n\naxiom=\"X\"\nrules=list(\"X\"=\"F-[[X]+X]+F[+FX]-X\", \"F\"=\"FF\")\nangle=22.5\ndepth=6\n\n\nfor (i in 1:depth) axiom=gsubfn(\".\", rules, axiom)\n\nactions=str_extract_all(axiom, \"\\\\d*\\\\+|\\\\d*\\\\-|F|L|R|\\\\[|\\\\]|\\\\|\") %>% unlist\n\nstatus=data.frame(x=numeric(0), y=numeric(0), alfa=numeric(0))\npoints=data.frame(x1 = 0, y1 = 0, x2 = NA, y2 = NA, alfa=90, depth=1)\n\n\n# Generating data\n# Note: may take a minute or two\n\nfor (action in actions)\n{\n  if (action==\"F\")\n  {\n    x=points[1, \"x1\"]+cos(points[1, \"alfa\"]*(pi/180))\n    y=points[1, \"y1\"]+sin(points[1, \"alfa\"]*(pi/180))\n    points[1,\"x2\"]=x\n    points[1,\"y2\"]=y\n    data.frame(x1 = x, y1 = y, x2 = NA, y2 = NA,\n               alfa=points[1, \"alfa\"],\n               depth=points[1,\"depth\"]) %>% rbind(points)->points\n  }\n  if (action %in% c(\"+\", \"-\")){\n    alfa=points[1, \"alfa\"]\n    points[1, \"alfa\"]=eval(parse(text=paste0(\"alfa\",action, angle)))\n  }\n  if(action==\"[\"){\n    data.frame(x=points[1, \"x1\"], y=points[1, \"y1\"], alfa=points[1, \"alfa\"]) %>%\n      rbind(status) -> status\n    points[1, \"depth\"]=points[1, \"depth\"]+1\n  }\n\n  if(action==\"]\"){\n    depth=points[1, \"depth\"]\n    points[-1,]->points\n    data.frame(x1=status[1, \"x\"], y1=status[1, \"y\"], x2=NA, y2=NA,\n               alfa=status[1, \"alfa\"],\n               depth=depth-1) %>%\n      rbind(points) -> points\n    status[-1,]->status\n  }\n}\n\nggplot() +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y2),\n               lineend = \"round\",\n               color=\"deeppink4\", # Set your own Fall color?\n               data=na.omit(points)) +\n  coord_fixed(ratio = 1) +\n  theme_void() # No grid nor axes\n\n\n\n\n\n\n\n\n\nQ3. Write a critique on a chart in published work (book/article/news website)\nThe following graph is a graph posted on ‘news1’, one of the Korean media. This shows Korea’s GDP growth over the past decade in percent.\n\nWhen we first looked at this graph, it seems that Korea’s GDP growth has fluctuated in recent years. It also appears to have declined sharply. But if we look closely at the graph, we can see that there is a trick. If you look at the graph’s x-axis, the years are not increasing from left to right. In this graph, the years are increasing from right to left. Taking this into account and looking at the graph again, Korea’s GDP growth did not change much. Most people unconsciously understand the passage of time from left to right. Therefore, the graph expressed in this way is highly likely to cause people’s misunderstand."
  },
  {
    "objectID": "assignment10.html",
    "href": "assignment10.html",
    "title": "assignment10",
    "section": "",
    "text": "Data Colloquium\n\n\nReplicate the plots in R\nDr. Patrick Brandt\n\n#######################################################################\n# Simulated data example\n#######################################################################\n# Do a simulation example first -- breaks in a regression, no dynamics\nset.seed(123)\ny1 <- rnorm(50, mean=0, sd=1)     # Break at 50\ny2 <- rnorm(100, mean=2, sd=0.5)  # Break at 150\ny3 <- rnorm(50, mean=-1, sd=2)\ny <- c(y1,y2,y3)\nplot(ts(y))\n\n# Fit the breakpoint models\nlibrary(strucchange)\n\nWarning: package 'strucchange' was built under R version 4.0.5\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.0.4\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: sandwich\n\n\nWarning: package 'sandwich' was built under R version 4.0.5\n\n\n\n\n# One break\nsystem.time(M1serial <- breakpoints(y ~ 1, h=0.05, breaks=1))\n\n   user  system elapsed \n   0.01    0.00    0.02 \n\n# Two break model\nsystem.time(M2serial <- breakpoints(y ~ 1, h=0.05, breaks=2))\n\n   user  system elapsed \n   0.07    0.00    0.10 \n\n# Three break model\nsystem.time(M3serial <- breakpoints(y ~ 1, h=0.05, breaks=3))\n\n   user  system elapsed \n   0.16    0.00    0.16 \n\n# Summarize the results\nsummary(M1serial)\n\n\n     Optimal (m+1)-segment partition: \n\nCall:\nbreakpoints.formula(formula = y ~ 1, h = 0.05, breaks = 1)\n\nBreakpoints at observation number:\n           \nm = 1   152\n\nCorresponding to breakdates:\n            \nm = 1   0.76\n\nFit:\n               \nm   0     1    \nRSS 549.9 356.8\nBIC 780.5 704.5\n\nsummary(M2serial)\n\n\n     Optimal (m+1)-segment partition: \n\nCall:\nbreakpoints.formula(formula = y ~ 1, h = 0.05, breaks = 2)\n\nBreakpoints at observation number:\n              \nm = 1      152\nm = 2   50 152\n\nCorresponding to breakdates:\n                 \nm = 1        0.76\nm = 2   0.25 0.76\n\nFit:\n                     \nm   0     1     2    \nRSS 549.9 356.8 234.3\nBIC 780.5 704.5 631.0\n\nsummary(M3serial)\n\n\n     Optimal (m+1)-segment partition: \n\nCall:\nbreakpoints.formula(formula = y ~ 1, h = 0.05, breaks = 3)\n\nBreakpoints at observation number:\n                  \nm = 1      152    \nm = 2   50 152    \nm = 3   50 150 174\n\nCorresponding to breakdates:\n                      \nm = 1        0.76     \nm = 2   0.25 0.76     \nm = 3   0.25 0.75 0.87\n\nFit:\n                           \nm   0     1     2     3    \nRSS 549.9 356.8 234.3 226.3\nBIC 780.5 704.5 631.0 634.7\n\n\n\n#########################################\n# RW intervention example\n#########################################\nset.seed(1234)\nx <- arima.sim(list(ar=c(0.9, -0.3)), n = 1000, \n               innov = c(rnorm(333), runif(333,-0.5,0.55) + rnorm(333), rnorm(334)))\n\n# Make a pretty plot\nplot(x)\nabline(v = 333, col = \"red\", lwd=2); abline(v=666, col = \"red\", lwd=2)"
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "Assignment2",
    "section": "",
    "text": "Data Visualization Assignment 2.\n\nUsing the happy planet data set\n\n\n#########################################\nrm(list=ls())                          # Clear environment\n\n\n\nhpi_df <- read.csv(\"HPI.csv\", header = TRUE)\n\ncolnames(hpi_df)<-c(\"hpi_rank\",\"country\",\"iso\",\"year\",\n                 \"continent\", \"population\", \"life_expectancy\",\n                 \"ladder_of_life\", \"ecological_footprint\",\n                 \"hpi\", \"biocapacity_for_year\", \"gdp\")\n\nhpi2_df <- na.omit(hpi_df)\n\n## Start plotting from basics \n#  plotting functions.\nyear <- c(2013, 2014, 2015, 2016, 2017, 2018, 2019)\nhpi_score <- aggregate(hpi ~ year, hpi2_df, mean)\nlife_score  <- aggregate(life_expectancy ~ year, hpi2_df, mean)\nhpi_score <- c(hpi_score$hpi)\nlife_score <- c(life_score$life_expectancy)\n\n# Setting the parameter (3 rows by 2 cols)\npar(mfrow=c(3, 2))\n\n# Setting label orientation, margins c(bottom, left, top, right) & text size\npar(las=1, mar=c(4, 4, 2, 4), cex=.7) \nplot.new()\nplot.window(range(year), c(40, 80))\nlines(year, hpi_score)\nlines(year, life_score)\npoints(year, hpi_score, pch=17, bg = \"blue\", cex=1) # Try different cex value?  \npoints(year, life_score, pch=21, bg =\"red\", cex=1)  # Different background color\npar(col=\"gray50\", fg=\"gray50\", col.axis=\"gray50\")\naxis(1, at=seq(2013, 2019, 2)) # What is the first number standing for?\naxis(2, at=seq(40, 80, 10))\naxis(4, at=seq(40, 80, 10))\nbox(bty=\"u\")\nmtext(\"year\", side=1, line=2, cex=0.8)\nmtext(\"HPI\", side=2, line=2, las=0, cex=0.8)\nmtext(\"Life Exp\", side=4, line=2, las=0, cex=0.8)\ntext(4, 5, \"Bird 131\")\npar(mar=c(5.1, 4.1, 4.1, 2.1), col=\"black\", fg=\"black\", col.axis=\"black\")\n\n\n######## Histogram ########\n\n# Make sure no Y exceed [-3.5, 3.5]\npar(mar=c(4.5, 4.1, 3.1, 0))\nhist(hpi2_df$hpi, breaks=seq(floor(min(hpi2_df$hpi)),\n                             ceiling(max(hpi2_df$hpi))), \n     main=\"Height histogram\", xlab=\"HPI\", \n     col=\"gray80\", freq=FALSE)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n\n####### Barplot ######\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsummary(hpi2_df$gdp)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   751.7   4984.0  12874.5  21034.2  31201.9 114304.0 \n\nhpi3_df <- hpi2_df %>%\n  mutate(gdp_lev = ifelse(hpi2_df$gdp >= 31202, 'high',\n                           ifelse(hpi2_df$gdp >= 4985, 'middle',\n                                  'low')))\n\nsummary(hpi2_df$hpi)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  22.35   38.32   44.24   44.05   49.88   64.73 \n\nhpi3_df <- hpi3_df %>%\n  mutate(hpi_lev = ifelse(hpi2_df$hpi > 49, 'good',\n                  ifelse(hpi2_df$hpi > 39, 'average',\n                         'bad')))\n\ngdp_sub_h <- subset(hpi3_df, gdp_lev == \"high\")\naggregate(gdp_lev ~ hpi_lev, gdp_sub_h, length)\n\n  hpi_lev gdp_lev\n1 average     122\n2     bad      50\n3    good      75\n\ngdp_sub_m <- subset(hpi3_df, gdp_lev == \"middle\")\naggregate(gdp_lev ~ hpi_lev, gdp_sub_m, length)\n\n  hpi_lev gdp_lev\n1 average     223\n2     bad      96\n3    good     175\n\ngdp_sub_l <- subset(hpi3_df, gdp_lev == \"low\")\naggregate(gdp_lev ~ hpi_lev, gdp_sub_l, length)\n\n  hpi_lev gdp_lev\n1 average      85\n2     bad     134\n3    good      28\n\nhpi_le <- c(\"average\", \"bad\", \"good\")\nhigh <- c(122, 50, 75)\nmiddle <- c(223, 96, 175)\nlow <- c(85, 134, 28)\n\nbar_df <- data.frame(high, middle, low)\nrownames(bar_df)=hpi_le\n\npar(mar=c(2, 3.1, 2, 2.1))\nmidpts <- barplot(as.matrix(bar_df), names = rep(\"\", 3),\n                  col = c(\"gray\", \"red\", \"blue\"))\nlegend(\"topright\", inset=.02,\n       c(\"average\",\"bad\", \"good\"), fill = c(\"gray\", \"red\", \"blue\"), \n       horiz=FALSE, cex=0.5)\nmtext(\"GDP per capita\", side=3, line=0.0, cex=0.5)\nmtext(sub(\" \", \"\\n\", colnames(bar_df)),\n      at=midpts, side=1, line=0.5, cex=0.5)\n\npar(mar=c(5.1, 4.1, 4.1, 2.1))  \n\n\n###### Boxplot ######\npar(mar=c(2, 4, 1, 0.5))\nboxplot(hpi3_df$hpi ~ hpi3_df$gdp_lev, data = hpi3_df,\n        boxwex = 0.4, at = 1:3 - 0.2,\n        subset= hpi3_df$hpi_lev == \"good\", col=\"blue\",\n        xlab=\"\",\n        ylab=\"HPI\", ylim=c(20,70))\nmtext(\"GDP per capita\", side=1, line=1.8, cex=0.5)\n\nboxplot(hpi3_df$hpi ~ hpi3_df$gdp_lev, data = hpi3_df, add = TRUE,\n        boxwex = 0.4, at = 1:3 + 0.2,\n        subset= hpi3_df$hpi_lev == \"bad\", col=\"red\")\nlegend(\"bottomleft\", inset=.02,\n       c(\"good\",\"bad\"), fill = c(\"blue\", \"red\"), horiz=TRUE, cex=0.5)\npar(mar=c(5.1, 4.1, 4.1, 2.1))\n\n###### Persp ######\npar(mar=c(0.5, 0.5, 0, 0), lwd=0.5)\nx <- y <- seq(-10, 10, length = 50);\nz <- outer(x, y,\n           function(x,y) {\n             r <- sqrt(x^2 + y^2)+3;\n             cos(r)/r\n           });\n\npersp(x, y, z,\n      theta  = 20,        # Rotation about z-axis, in degrees\n      phi    = 30,        # Rotation about x-axis, in degrees\n      expand = 0.5,        # Shrinking/growing of z values\n      shade  = 0.3)\n\npar(mar=c(5.1, 4.1, 4.1, 2.1), lwd=1)\n\n\n# Piechart\npar(mar=c(0, 2, 1, 2), xpd=FALSE, cex=0.5)\npie.sales <- c(0.11, 0.06, 0.23, 0.11, 0.12, 0.37)\nnames(pie.sales) <- c(\"Africa\", \"Asia\",\n                      \"Europe\", \"Oceania\", \"Others\", \"S.America\")\npie(pie.sales, col = rainbow(7))"
  },
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "Assignment3",
    "section": "",
    "text": "Compare the regression models\n\n## Data Visualization\n## Sept 21 2022\n## Dohyo Jeong\n\nrm(list=ls()) \n\n## Anscombe (1973) Quartlet\n\ndata(anscombe)  # Load Anscombe's data\n\n# Create four model objects\nlm1 <- lm(y1 ~ x1, data=anscombe)\nlm2 <- lm(y2 ~ x2, data=anscombe)\nlm3 <- lm(y3 ~ x3, data=anscombe)\nlm4 <- lm(y4 ~ x4, data=anscombe)\n\n## Fancy version (per help file)\n\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] <- as.name(paste0(\"y\", i))\n  ##      ff[[3]] <- as.name(paste0(\"x\", i))\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(>F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"blue\", pch = 21, bg = \"blue\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"red\", lwd = 1.5)\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\npar(op)\n\n\n\nExample of overfitting with finetune\n\nx <- seq(0, 2, by = 0.025)\ny <- 5 + 3*x^2 + 100*x^3 + rnorm(length(x), 0, 50)\nz <- x^2\n\nset.seed(2022)\n\nlinearmodel <- lm(y ~ x) #model fitting\n\ntestx <- seq(1.1, 1.5, by = 0.025)\ntesty <- 5 + 3*testx^2 + 100*(testx)^3 + rnorm(length(testx), 0, 20)\npredict_linear <- predict(linearmodel, list(x= testx)) #prediction on test data set\n\nquadraticmodel <- lm(y~ x + z) #fitting\npredict_quadratic = predict(quadraticmodel, list(x = testx, z = testx^2)) #prediction on test data set\n\nsmoothspline <- smooth.spline(x,y,df = 50) #fitting \npredict_spline <- predict(smoothspline, testx)$y #prediction on test data set\n\nseq <- seq(min(x), max(x), by = 0.001)\npredict <- predict(quadraticmodel, list(x = seq, z = seq^2))\n\npar(mfrow=c(1,1))\nplot(x,y, xlab = \"X\", ylab = \"Y\", main = \"Example of Overfitting with finetune\" )\nabline(linearmodel, col = \"red\", lwd = 1)\nlines(seq,predict, col = \"blue\", lwd = 2)\nlines(smoothspline, col = \"green\", lwd = 2)\n\n\n\n\n\n\nHappy Planet Index with ggplot\n\nhpi <- read.csv(\"HPI_GDP.csv\")\n\nlibrary(ggplot2)\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'hms'\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv tibble  3.1.4     v dplyr   1.0.7\nv tidyr   1.1.3     v stringr 1.4.0\nv readr   1.4.0     v forcats 0.5.1\nv purrr   0.3.4     \n\n\nWarning: package 'tibble' was built under R version 4.0.5\n\n\nWarning: package 'tidyr' was built under R version 4.0.5\n\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: package 'stringr' was built under R version 4.0.5\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nhappy <- hpi %>% \n  filter(year == 2017) %>% \n  ggplot(aes(y = HPI, x = GDP, colour = Continent)) +\n  geom_point(alpha = 0.3) +\n  theme_bw() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_colour_brewer(palette = \"Set1\") +\n  labs(x = \"GDP per capita\",\n       y = \"Happy Index\",\n       title = \"Economics and Happy\",\n       subtitle = \"Happy Planet Index, 2017\",\n       caption = Sys.Date())\n\nhappy\n\n`geom_smooth()` using formula 'y ~ x'\n\n\nWarning: Removed 8 rows containing non-finite values (stat_smooth).\n\n\nWarning: Removed 8 rows containing missing values (geom_point)."
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "Assignment4",
    "section": "",
    "text": "Data Visualization Hackathon\n\nHackathon (Assignment 4)\n\nrm(list=ls())\n\nN<- read.csv(\"Sampling Example2.csv\")\nVoting <- N$Likeliness.you.will.vote\nGenre <- N$Music.Taste\nAge <- N$Age\nParty <- N$Political.Party...Liberal..0..Conservative..1.\n\nlibrary(ggplot2)\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'hms'\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv tibble  3.1.4     v dplyr   1.0.7\nv tidyr   1.1.3     v stringr 1.4.0\nv readr   1.4.0     v forcats 0.5.1\nv purrr   0.3.4     \n\n\nWarning: package 'tibble' was built under R version 4.0.5\n\n\nWarning: package 'tidyr' was built under R version 4.0.5\n\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: package 'stringr' was built under R version 4.0.5\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(viridis)\n\nWarning: package 'viridis' was built under R version 4.0.5\n\n\nLoading required package: viridisLite\n\n\nWarning: package 'viridisLite' was built under R version 4.0.5\n\nlibrary(gridExtra)\n\nWarning: package 'gridExtra' was built under R version 4.0.5\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(cowplot)\n\nWarning: package 'cowplot' was built under R version 4.0.5\n\np1<- ggplot(N,\n       aes(x=`Voting`,\n           ))+\n  geom_bar(position='dodge') +\n  scale_colour_brewer(palette = \"Set1\") +\n  theme_bw() +\n  labs(x = \"On a Scale of 1-to-5 How Likely Are You to Vote?\",\n       y = \"count\",\n       title = \"Likeliness of Voting\",\n       caption = Sys.Date())\np1\n\n\n\n\n\n#2\n\np2<- ggplot(N,\n            aes(x=`Genre`,\n            ))+\n  geom_bar(position='dodge') +\n  scale_colour_brewer(palette = \"Set1\") +\n  theme_bw() +\n  labs(x = \"Preferred Genre?\",\n       y = \"count\",\n       title = \"Genre\",\n       caption = Sys.Date())\n\np3<- ggplot(N,\n            aes(x=`Age`,\n            ))+\n  geom_bar(position='dodge') +\n  scale_colour_brewer(palette = \"Set1\") +\n  theme_bw() +\n  labs(x = \"How old are you?\",\n       y = \"count\",\n       title = \"Age\",\n       caption = Sys.Date())\n\n\n\nggdraw() +\n  draw_plot(p2, x = 0, y = .5, width = .5, height = .5) +\n  draw_plot(p3, x = .5, y = .5, width = .5, height = .5) +\n  draw_plot(p1, x = 0, y = 0, width = 1, height = 0.5) +\n  draw_plot_label(label = c(\"A\", \"B\", \"C\"), size = 8,\n                  x = c(0, 0.5, 0), y = c(1, 1, 0.5))\n\n\n\n\nGraph A\nIn terms of music genre, Latin and Pop music are the most preferred, followed closely by R & B, and Classical, while Country and Other genres have low preferences.\nGraph B\nThe age distribution indicates that most individuals are 55 years old, followed closely by individuals aged 31 years, 28 years, and 22 years respectively. The fewest individuals are aged 58 years, 26 years, and 24 years respectively. While other age groups are fairly distributed\nGraph C\nOn a scale of 1 to 5 where 1 indicates a strong disagreement to voting and 5 indicates a strong preference for voting, most respondents indicate their preference of being undecided to being not likely to vote, while those that indicate stronger preferences towards voting are fewer within the distribution.\nComparing graph C and Likeliness of voting\nGraph c and likeliness of voting are showing the same information but graph C uses shorter bars and the second graph uses longer bars. The graph that uses longer bars helps viewers to grasp the information more easily. Also, it shows the count more precisely and the difference between scales in more detail.\n\nGraph #1\n\n### Data Visualization\n### Hackathon (assignment 4)\n### Dohyo Jeong\n### Sept/27/2022\n\n# Table 1\nN <- read.csv(\"samplingExample.csv\", header = TRUE)\n\ncolnames(N)<-c(\"Name\", \"Music Taste\", \"Likeliness of Voting\")\n\nlibrary(ggplot2)\nggplot(N,\n       aes(x=`Likeliness of Voting`,\n           fill=`Music Taste`))+\n  geom_bar(position='dodge') +\n  scale_colour_brewer(palette = \"Set1\") +\n  theme_bw() +\n  labs(x = \"On a Scale of 1-to-5 How Likely Are You to Vote?\",\n       y = \"count\",\n       title = \"Likeliness of Voting\",\n       caption = Sys.Date())\n\n\n\n\nGraph 1.\nPeople with music taste B are likely to vote more than people with music taste A, C.\nAlso, people with music taste B are more favorable to voting, and people with music taste A mostly voted for 1 and 2. Music taste C has no significant difference between the scales of likeliness of voting.\n\n\n\n\n\nGraph #2\n\n### Data Visualization\n### Hackathon (assignment 4)\n### Dohyo Jeong\n### Sept/27/2022\n\n# Table 2\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(gridExtra)\nlibrary(cowplot)\n\nproperty_df <- read.csv(\"as4_data.csv\", header = TRUE)\ncolnames(property_df)<-c(\"nation\", \"year\", \"property\",\n                         \"corruption\", \"Developed\", \"Country\",\n                         \"corruption_lev\")\n\nproperty_df <- na.omit(property_df)\n\n\np1 <- property_df %>% \n  filter(year == 2009) %>% \n  ggplot(aes(y = property, x = corruption , colour = Country)) +\n  geom_point(alpha = 0.3) +\n  theme_bw() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_colour_brewer(palette = \"Set1\") +\n  labs(x = \"Political Corruption\",\n       y = \"Property Right\",\n       title = \"Relationship between Property Right and Corruption\",\n       subtitle = \"2009\",\n       caption = Sys.Date()) +\n  theme(legend.position = \"right\",\n        axis.title = element_text(size = 6),\n        title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n####\np2 <- ggplot(property_df, aes(x = property_df$property))+\n  geom_density(aes(group = Country, fill = Country), alpha = 0.6) +\n  theme_bw() +\n  scale_fill_viridis(discrete = TRUE) +\n  scale_color_viridis(discrete = TRUE) +\n  labs(x = \"Property Right\",\n       y = \"Density\",\n       title = \"Property Right Distribution by Country\") +\n  theme(axis.title = element_text(size = 6),\n        title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n####\npr_df <- property_df %>%\n  mutate(pro_lev = ifelse(property_df$property >= 70, 'high',\n                          ifelse(property_df$property >= 30, 'middle',\n                                 'low')))\n\np3 <- pr_df %>% \n  filter(year == 2009) %>%\n  ggplot(aes(x = pro_lev, fill = Country))+\n  geom_bar(position='identity') +\n  scale_colour_brewer(palette = \"Set1\") +\n  theme_bw() +\n  labs(x = \"Property Right\",\n       y = \"count\",\n       title = \"Property Right by country\") +\n  coord_flip() +\n  theme(axis.title = element_text(size = 6),\n        title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n  \n####\n\nggdraw() +\n  draw_plot(p2, x = 0, y = .5, width = .5, height = .5) +\n  draw_plot(p3, x = .5, y = .5, width = .5, height = .5) +\n  draw_plot(p1, x = 0, y = 0, width = 1, height = 0.5) +\n  draw_plot_label(label = c(\"A\", \"B\", \"C\"), size = 8,\n                  x = c(0, 0.5, 0), y = c(1, 1, 0.5))\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nGraph 2 (a)\nBased on the distribution of property rights, there is a significant mean difference between developed and developing countries. This implies that developed countries have more strict policies toward property rights and as countries become more developed there are higher chances that the country will protect their property rights.\nComparing graph 2(a) and 2(b)\nRegarding property rights by country, we see that a majority of developing nations have ‘middle’ level property rights; whereas, all developed nations have “high” level property rights. Additionally, developing states have varying degrees of property rights, with ‘high’ level rights being the lowest amount possessed, and ‘middle’ rights being the highest amount possessed. This graph supports the literature; where, developing nations lack the institutional structure to possess high-level property rights for its citizenry while developed nations hold the contrary to be true.\nAlso, it is more convenient to see the count between developed and developing countries via graph 2(B) but (A) shows more information such as the mean, variance, skewness, etc. This allows us to understand the property rights of developed and developing countries in more depth.\nGraph 2 (c).\nThis scatter plot with two lines shows the negative correlation between property rights and political corruption for both developed and developing countries. Based on the slope of the developed countries, it is shown that the correlation between property right and corruption is less sensitive, whereas the correlation between property right and corruption in developing countries have a stronger relationship. Moreover, blue dots are gathered around a higher political corruption rate, implying that developing countries tend to have higher political corruption than developed countries."
  },
  {
    "objectID": "assignment5.html",
    "href": "assignment5.html",
    "title": "assignment5",
    "section": "",
    "text": "Data Visualization Assignment 5\n\nBar Chart\n\n### assignment 5\n### Dohyo Jeong\n\nlibrary(ggplot2)\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'hms'\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv tibble  3.1.4     v dplyr   1.0.7\nv tidyr   1.1.3     v stringr 1.4.0\nv readr   1.4.0     v forcats 0.5.1\nv purrr   0.3.4     \n\n\nWarning: package 'tibble' was built under R version 4.0.5\n\n\nWarning: package 'tidyr' was built under R version 4.0.5\n\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: package 'stringr' was built under R version 4.0.5\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(RColorBrewer)\n\n\nhpi <- read.csv(\"hpi_count.csv\")\n\ncolnames(hpi) <- c(\"hpi\", \"gdp\", \"continent\", \"year\")\n\nhpi <- hpi %>% mutate(year = as.character(year))\n\np1 <- ggplot(hpi,\n       aes(x = continent,\n           group = year,\n           fill = year))+\n  scale_fill_brewer(palette = \"Paired\") +\n  geom_bar(position='dodge') +\n  coord_flip() +\n  labs(title = \"Change of High Happiness Frequency by Continent\") +\n  theme_classic()\n\np1\n\n\n\n\n\n\nColumn Chart\n\np2 <- ggplot(hpi,\n             aes(x = year,\n                 group = continent,\n                 fill = continent))+\n  scale_fill_manual(breaks = c(\"Asia\", \"Europe\", \"S.Africa\"),\n                    values = c(\"lightgreen\", \"lightblue\", \"orange\")) +\n  geom_bar(position='stack') +\n  labs(title = \"Continents with high happiness index by year\") +\n  theme_classic()\np2\n\n\n\n\n\n\nCircular Area Chart\n\np3 <- ggplot(hpi, aes(x = hpi, fill = continent)) +\n  geom_histogram(binwidth = 15, boundary = -7.5) +\n  coord_polar() +\n  scale_x_continuous(limits = c(20, 70)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  xlab(\"Happy index\")+\n  labs(title = \"Happy index by Continent\")\n\np3\n\nWarning: Removed 6 rows containing missing values (geom_bar)."
  },
  {
    "objectID": "assignment6.html",
    "href": "assignment6.html",
    "title": "Assignment 6",
    "section": "",
    "text": "Make Shiny App\n\n\n\n\n\nScreengrab for Assignment 6 Shiny App\n\n#Formatting page \n\n# install.packages(\"shiny\")\nlibrary(\"shiny\")\n\n\n# First component: User interface (ui)\nui <- fluidPage (\n  tags$h1(\"Data Visualization App\"), \n  tags$img(src = \"\"),\n   # tags$hr(),\n   # tags$br(),\n  tags$h1(strong(\"Dohyo Jeong\")),\n  tags$p(em(\"School of Economic, Political and Policy Sciences\")),\n  tags$a(em(href=\"https://utdallas.edu\", \"University of Texas at Dallas\")),\n  tags$a(href=\"https://dohyojeong.github.io/\", \"Dohyo Jeong Homepage\"))\n\nThis version of 'bslib' is designed to work with 'rmarkdown' >= 2.7.\n    Please upgrade via install.packages('rmarkdown').\n\n\n\n# Second component: server\n\nserver <- function(input , output){} \n\n# Calling the shinyapp\n\nshinyApp(ui = ui , server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\n\n#load datsets \n\ndata(mtcars)\ndata(USArrests)\ndata(uspop)\n\n\n# Define UI for dataset viewer app ----\nui <- fluidPage(\n  # App title ----\n  titlePanel(\"Datasets\"),\n  \n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n    \n    # Sidebar panel for inputs ----\n    sidebarPanel(\n      \n      # Input: Text for providing a caption ----\n      # Note: Changes made to the caption in the textInput control\n      # are updated in the output area immediately as you type\n      textInput(inputId = \"caption\",\n                label = \"Caption:\",\n                value = \"Datasets\"),\n      \n      # Input: Selector for choosing dataset ----\n      selectInput(inputId = \"dataset\",\n                  label = \"Choose a dataset:\",\n                  choices = c(\"mtcars\", \"USArrests\",\"uspop\")),\n      \n      # Input: Numeric entry for number of obs to view ----\n      numericInput(inputId = \"obs\",\n                   label = \"Number of observations to view:\",\n                   min=0,\n                   value = 10)\n      \n    ),\n    \n    # Main panel for displaying outputs ----\n    mainPanel(\n      \n      # Output: Formatted text for caption ----\n      h3(textOutput(\"caption\", container = span)),\n      \n      # Output: Verbatim text for data summary ----\n      verbatimTextOutput(\"summary\"),\n      \n      # Output: HTML table with requested number of observations ----\n      tableOutput(\"view\")\n      \n    )\n  )\n)\n\n\n# Define server logic to summarize and view selected dataset ----\nserver <- function(input, output) {\n  \n  # Return the requested dataset ----\n  # By declaring datasetInput as a reactive expression we ensure\n  # that:\n  #\n  # 1. It is only called when the inputs it depends on changes\n  # 2. The computation and result are shared by all the callers,\n  #    i.e. it only executes a single time\n  datasetInput <- reactive({\n    switch(input$dataset,\n           \"mtcars\" = mtcars,\n           \"US Arrests\"= USArrests,\n           \"US Population\"= uspop)\n  })\n  \n  # Create caption ----\n  # The output$caption is computed based on a reactive expression\n  # that returns input$caption. When the user changes the\n  # \"caption\" field:\n  #\n  # 1. This function is automatically called to recompute the output\n  # 2. New caption is pushed back to the browser for re-display\n  #\n  # Note that because the data-oriented reactive expressions\n  # below don't depend on input$caption, those expressions are\n  # NOT called when input$caption changes\n  output$caption <- renderText({\n    input$caption\n  })\n  \n  # Generate a summary of the dataset ----\n  # The output$summary depends on the datasetInput reactive\n  # expression, so will be re-executed whenever datasetInput is\n  # invalidated, i.e. whenever the input$dataset changes\n  output$summary <- renderPrint({\n    dataset <- datasetInput()\n    summary(dataset)\n  })\n  \n  # Show the first \"n\" observations ----\n  # The output$view depends on both the databaseInput reactive\n  # expression and input$obs, so it will be re-executed whenever\n  # input$dataset or input$obs is changed\n  output$view <- renderTable({\n    head(datasetInput(), n = input$obs)\n  })\n  \n}\n\n\n# Create Shiny app ----\nshinyApp(ui, server)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "assignment7.html",
    "href": "assignment7.html",
    "title": "Assignment 7",
    "section": "",
    "text": "Graphs with Shiny App\nScreengrab for Assignment 7 Shiny App\n\n#Formatting page \n\n# install.packages(\"shiny\")\nlibrary(\"shiny\")\n\n\n# First component: User interface (ui)\nui <- fluidPage (\n  tags$h1(\"Data Visualization App\"), \n  tags$img(src = \"\"),\n   # tags$hr(),\n   # tags$br(),\n  tags$h1(strong(\"Dohyo Jeong\")),\n  tags$p(em(\"School of Economic, Political and Policy Sciences\")),\n  tags$a(em(href=\"https://utdallas.edu\", \"University of Texas at Dallas\")),\n  tags$a(href=\"https://dohyojeong.github.io/\", \"Dohyo Jeong Homepage\"))\n\nThis version of 'bslib' is designed to work with 'rmarkdown' >= 2.7.\n    Please upgrade via install.packages('rmarkdown').\n\n\n\n# Second component: server\n\nserver <- function(input , output){} \n\n# Calling the shinyapp\n\nshinyApp(ui = ui , server = server)\n\nShiny applications not supported in static R Markdown documents\n\n\n\n#load datsets \n\ndata(mtcars)\ndata(USArrests)\ndata(uspop)\n\n\n# Define UI for dataset viewer app ----\nui <- fluidPage(\n  # App title ----\n  titlePanel(\"Datasets\"),\n  \n  # Sidebar layout with input and output definitions ----\n  sidebarLayout(\n    \n    # Sidebar panel for inputs ----\n    sidebarPanel(\n      \n      # Input: Text for providing a caption ----\n      # Note: Changes made to the caption in the textInput control\n      # are updated in the output area immediately as you type\n      textInput(inputId = \"caption\",\n                label = \"Caption:\",\n                value = \"Datasets\"),\n      \n      # Input: Selector for choosing dataset ----\n      selectInput(inputId = \"dataset\",\n                  label = \"Choose a dataset:\",\n                  choices = c(\"mtcars\", \"USArrests\",\"uspop\")),\n      \n      # Input: Numeric entry for number of obs to view ----\n      numericInput(inputId = \"obs\",\n                   label = \"Number of observations to view:\",\n                   min=0,\n                   value = 10)\n      \n    ),\n    \n    # Main panel for displaying outputs ----\n    mainPanel(\n      \n      # Output: Formatted text for caption ----\n      h3(textOutput(\"caption\", container = span)),\n      \n      # Output: Verbatim text for data summary ----\n      verbatimTextOutput(\"summary\"),\n      \n      # Output: HTML table with requested number of observations ----\n      tableOutput(\"view\")\n      \n    )\n  )\n)\n\n\n# Define server logic to summarize and view selected dataset ----\nserver <- function(input, output) {\n  \n  # Return the requested dataset ----\n  # By declaring datasetInput as a reactive expression we ensure\n  # that:\n  #\n  # 1. It is only called when the inputs it depends on changes\n  # 2. The computation and result are shared by all the callers,\n  #    i.e. it only executes a single time\n  datasetInput <- reactive({\n    switch(input$dataset,\n           \"mtcars\" = mtcars,\n           \"US Arrests\"= USArrests,\n           \"US Population\"= uspop)\n  })\n  \n  # Create caption ----\n  # The output$caption is computed based on a reactive expression\n  # that returns input$caption. When the user changes the\n  # \"caption\" field:\n  #\n  # 1. This function is automatically called to recompute the output\n  # 2. New caption is pushed back to the browser for re-display\n  #\n  # Note that because the data-oriented reactive expressions\n  # below don't depend on input$caption, those expressions are\n  # NOT called when input$caption changes\n  output$caption <- renderText({\n    input$caption\n  })\n  \n  # Generate a summary of the dataset ----\n  # The output$summary depends on the datasetInput reactive\n  # expression, so will be re-executed whenever datasetInput is\n  # invalidated, i.e. whenever the input$dataset changes\n  output$summary <- renderPrint({\n    dataset <- datasetInput()\n    summary(dataset)\n  })\n  \n  # Show the first \"n\" observations ----\n  # The output$view depends on both the databaseInput reactive\n  # expression and input$obs, so it will be re-executed whenever\n  # input$dataset or input$obs is changed\n  output$view <- renderTable({\n    head(datasetInput(), n = input$obs)\n  })\n  \n}\n\n\n# Create Shiny app ----\nshinyApp(ui, server)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "assignment8.html",
    "href": "assignment8.html",
    "title": "assignment8",
    "section": "",
    "text": "Team Project Data with Descriptive table and Mapping\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\ntotal_df <- read.csv(\"total_merge.csv\")\ntotal_df <- rename(total_df, c(region=ï..name))\n\n#df17 <- total_df %>% filter(year == 2017)\n#df18 <- total_df %>% filter(year == 2018)\n#df19 <- total_df %>% filter(year == 2019)\n#df20 <- total_df %>% filter(year == 2020)\n\nsummary(total_df)\n\n    region              code              code2                year     \n Length:868         Length:868         Length:868         Min.   :2017  \n Class :character   Class :character   Class :character   1st Qu.:2018  \n Mode  :character   Mode  :character   Mode  :character   Median :2018  \n                                                          Mean   :2018  \n                                                          3rd Qu.:2019  \n                                                          Max.   :2020  \n                                                                        \n      gdp                age            gender           edu        \n Min.   :   270.7   Min.   :47.32   Min.   :24.33   Min.   : 37.92  \n 1st Qu.:  2318.3   1st Qu.:59.48   1st Qu.:49.64   1st Qu.: 86.79  \n Median :  6185.9   Median :64.69   Median :50.27   Median : 96.24  \n Mean   : 16036.3   Mean   :63.67   Mean   :49.90   Mean   : 92.45  \n 3rd Qu.: 19105.4   3rd Qu.:67.51   3rd Qu.:51.00   3rd Qu.:101.40  \n Max.   :181709.3   Max.   :85.26   Max.   :54.56   Max.   :129.40  \n NA's   :62         NA's   :96      NA's   :96      NA's   :415     \n     urban            voice           stability            effect        \n Min.   : 12.71   Min.   :-2.2100   Min.   :-3.01000   Min.   :-2.48000  \n 1st Qu.: 42.39   1st Qu.:-0.8225   1st Qu.:-0.63000   1st Qu.:-0.68250  \n Median : 61.95   Median : 0.0400   Median : 0.03500   Median :-0.09000  \n Mean   : 61.06   Mean   :-0.0203   Mean   :-0.03262   Mean   :-0.02262  \n 3rd Qu.: 80.74   3rd Qu.: 0.8100   3rd Qu.: 0.81250   3rd Qu.: 0.58250  \n Max.   :100.00   Max.   : 1.7300   Max.   : 1.93000   Max.   : 2.34000  \n NA's   :12       NA's   :64        NA's   :64         NA's   :64        \n   regulatory            law             corruption            hdi        \n Min.   :-2.36000   Min.   :-2.35000   Min.   :-1.91000   Min.   :0.0000  \n 1st Qu.:-0.70000   1st Qu.:-0.72250   1st Qu.:-0.75250   1st Qu.:0.5960  \n Median :-0.11500   Median :-0.14000   Median :-0.18500   Median :0.7410  \n Mean   :-0.01456   Mean   :-0.01729   Mean   :-0.02391   Mean   :0.7074  \n 3rd Qu.: 0.63000   3rd Qu.: 0.62250   3rd Qu.: 0.64000   3rd Qu.:0.8353  \n Max.   : 2.23000   Max.   : 2.08000   Max.   : 2.27000   Max.   :0.9620  \n NA's   :64         NA's   :64         NA's   :64         NA's   :88      \n    hdilev              altlev         attlevl             attotal       \n Length:868         Min.   :0.0000   Length:868         Min.   :  0.000  \n Class :character   1st Qu.:0.0000   Class :character   1st Qu.:  0.000  \n Mode  :character   Median :0.0000   Mode  :character   Median :  0.000  \n                    Mean   :0.2523                      Mean   :  4.283  \n                    3rd Qu.:0.0000                      3rd Qu.:  0.000  \n                    Max.   :7.0000                      Max.   :577.000  \n                                                                         \n     atwork            atfaci           attrans            covid     \n Min.   :  0.000   Min.   :  0.000   Min.   : 0.0000   Min.   :0.00  \n 1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.: 0.0000   1st Qu.:0.00  \n Median :  0.000   Median :  0.000   Median : 0.0000   Median :0.00  \n Mean   :  2.757   Mean   :  1.273   Mean   : 0.3064   Mean   :0.25  \n 3rd Qu.:  0.000   3rd Qu.:  0.000   3rd Qu.: 0.0000   3rd Qu.:0.25  \n Max.   :467.000   Max.   :244.000   Max.   :58.0000   Max.   :1.00  \n                                                                     \n     hdibi            inter             hdibi2           inter2       \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.3979   Mean   :0.08756   Mean   :0.1846   Mean   :0.04147  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n NA's   :104                        NA's   :88                        \n     stabi            inter3            lat             long        \n Min.   :0.0000   Min.   :0.0000   Min.   : 0.00   Min.   :  1.167  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:12.42   1st Qu.: 18.375  \n Median :1.0000   Median :0.0000   Median :21.25   Median : 45.000  \n Mean   :0.5369   Mean   :0.1348   Mean   :25.42   Mean   : 56.235  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:40.00   3rd Qu.: 80.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :72.00   Max.   :178.000  \n                                   NA's   :20      NA's   :20       \n      lat2             long2        \n Min.   :-41.000   Min.   :-175.00  \n 1st Qu.:  4.375   1st Qu.: -11.62  \n Median : 17.292   Median :  20.00  \n Mean   : 19.195   Mean   :  19.37  \n 3rd Qu.: 39.625   3rd Qu.:  50.73  \n Max.   : 72.000   Max.   : 178.00  \n NA's   :20        NA's   :20       \n\nmapdata <- map_data(\"world\")\n\n#mapdata <- merge(mapdata, total_df,\n#              by.x = 'region',\n#              by.y = 'region')\n\n\nmapdata <- left_join(mapdata, total_df, by=\"region\")\n\nmapdata19 <- mapdata %>% filter(year == 2019)\nmapdata20 <- mapdata %>% filter(year == 2020)\n\n\n#mapdata1<-mapdata %>% filter(!is.na(mapdata$Perc_vaccinated))\n\n\nmap19 <- ggplot(mapdata19, aes( x = long.x, y = lat.x, group=group)) +\n  geom_polygon(aes(fill = altlev), color = \"black\") +\n  theme_classic() +\n  labs(title=\"Health care Attack 2019\",\n       subtitle = \"Before COVID-19\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  labs(fill = \"Attack level\") +\n  theme(legend.title = element_text(color = \"black\", size = 8))+\n  theme(legend.text = element_text(color = \"black\", size = 7))+\n  scale_fill_gradient2(low = \"yellow\", high = \"red\", na.value = NA, \n                       limits = c(0,7), breaks = c(0,1,2,3,4,5,6,7))\n\n\nmap20 <- ggplot(mapdata20, aes( x = long.x, y = lat.x, group=group)) +\n  geom_polygon(aes(fill = altlev), color = \"black\") +\n  theme_classic() +\n  labs(title=\"Health care Attack 2020\",\n      subtitle = \"After COVID-19\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  labs(fill = \"Attack level\") +\n  theme(legend.title = element_text(color = \"black\", size = 8))+\n  theme(legend.text = element_text(color = \"black\", size = 7))+\n  scale_fill_gradient2(low = \"yellow\", high = \"red\", na.value = NA, \n                        limits = c(0,7), breaks = c(0,1,2,3,4,5,6,7))\n\n\nmap19\n\n\n\nmap20\n\n\n\n\n\n\nResults of Difference in Difference\n\nlibrary(dplyr)\ntotal_df <- read.csv(\"total_merge.csv\")\n\ntotal_df <- rename(total_df, c(region=ï..name))\n\ntotal_df [, \"lngdp\"] <- log(total_df$gdp)\n\ntotal_df <- rename(total_df, c(COVID19=covid))\ntotal_df <- rename(total_df, c(HDI=hdibi2))\ntotal_df <- rename(total_df, c(DID=inter2))\ntotal_df <- rename(total_df, c(c.corruption=corruption))\ntotal_df <- rename(total_df, c(Attack=altlev))\n\n\ndid_hdi <- lm(data = total_df, Attack ~ COVID19 + HDI + DID +\n            voice + stability + regulatory + law + c.corruption + \n            lngdp + age + gender + edu + urban + lat + long)\nsummary(did_hdi)\n\n\nCall:\nlm(formula = Attack ~ COVID19 + HDI + DID + voice + stability + \n    regulatory + law + c.corruption + lngdp + age + gender + \n    edu + urban + lat + long, data = total_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.9600 -0.1975 -0.0406  0.1263  3.3549 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.4150989  0.7623674  -0.544 0.586409    \nCOVID19       0.0350438  0.0734686   0.477 0.633628    \nHDI           0.5095907  0.1204774   4.230  2.9e-05 ***\nDID           0.0189895  0.1631567   0.116 0.907403    \nvoice         0.1150309  0.0420264   2.737 0.006474 ** \nstability    -0.4824986  0.0446560 -10.805  < 2e-16 ***\nregulatory   -0.1396615  0.0688228  -2.029 0.043089 *  \nlaw           0.0191420  0.0975459   0.196 0.844525    \nc.corruption  0.0903721  0.0706032   1.280 0.201285    \nlngdp         0.1614957  0.0498187   3.242 0.001288 ** \nage          -0.0017242  0.0068019  -0.253 0.800024    \ngender       -0.0153286  0.0077231  -1.985 0.047851 *  \nedu          -0.0001637  0.0025119  -0.065 0.948085    \nurban        -0.0057935  0.0015349  -3.775 0.000184 ***\nlat           0.0062986  0.0019105   3.297 0.001065 ** \nlong          0.0024836  0.0007238   3.431 0.000663 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4472 on 401 degrees of freedom\n  (451 observations deleted due to missingness)\nMultiple R-squared:  0.3784,    Adjusted R-squared:  0.3551 \nF-statistic: 16.27 on 15 and 401 DF,  p-value: < 2.2e-16\n\n\n\n\nPloty graph\n\nlibrary(dplyr)\ntotal_df <- read.csv(\"total_merge.csv\")\ntotal_df <- rename(total_df, c(region=ï..name))\n\n\n#stability\nsummary(total_df)\n\n    region              code              code2                year     \n Length:868         Length:868         Length:868         Min.   :2017  \n Class :character   Class :character   Class :character   1st Qu.:2018  \n Mode  :character   Mode  :character   Mode  :character   Median :2018  \n                                                          Mean   :2018  \n                                                          3rd Qu.:2019  \n                                                          Max.   :2020  \n                                                                        \n      gdp                age            gender           edu        \n Min.   :   270.7   Min.   :47.32   Min.   :24.33   Min.   : 37.92  \n 1st Qu.:  2318.3   1st Qu.:59.48   1st Qu.:49.64   1st Qu.: 86.79  \n Median :  6185.9   Median :64.69   Median :50.27   Median : 96.24  \n Mean   : 16036.3   Mean   :63.67   Mean   :49.90   Mean   : 92.45  \n 3rd Qu.: 19105.4   3rd Qu.:67.51   3rd Qu.:51.00   3rd Qu.:101.40  \n Max.   :181709.3   Max.   :85.26   Max.   :54.56   Max.   :129.40  \n NA's   :62         NA's   :96      NA's   :96      NA's   :415     \n     urban            voice           stability            effect        \n Min.   : 12.71   Min.   :-2.2100   Min.   :-3.01000   Min.   :-2.48000  \n 1st Qu.: 42.39   1st Qu.:-0.8225   1st Qu.:-0.63000   1st Qu.:-0.68250  \n Median : 61.95   Median : 0.0400   Median : 0.03500   Median :-0.09000  \n Mean   : 61.06   Mean   :-0.0203   Mean   :-0.03262   Mean   :-0.02262  \n 3rd Qu.: 80.74   3rd Qu.: 0.8100   3rd Qu.: 0.81250   3rd Qu.: 0.58250  \n Max.   :100.00   Max.   : 1.7300   Max.   : 1.93000   Max.   : 2.34000  \n NA's   :12       NA's   :64        NA's   :64         NA's   :64        \n   regulatory            law             corruption            hdi        \n Min.   :-2.36000   Min.   :-2.35000   Min.   :-1.91000   Min.   :0.0000  \n 1st Qu.:-0.70000   1st Qu.:-0.72250   1st Qu.:-0.75250   1st Qu.:0.5960  \n Median :-0.11500   Median :-0.14000   Median :-0.18500   Median :0.7410  \n Mean   :-0.01456   Mean   :-0.01729   Mean   :-0.02391   Mean   :0.7074  \n 3rd Qu.: 0.63000   3rd Qu.: 0.62250   3rd Qu.: 0.64000   3rd Qu.:0.8353  \n Max.   : 2.23000   Max.   : 2.08000   Max.   : 2.27000   Max.   :0.9620  \n NA's   :64         NA's   :64         NA's   :64         NA's   :88      \n    hdilev              altlev         attlevl             attotal       \n Length:868         Min.   :0.0000   Length:868         Min.   :  0.000  \n Class :character   1st Qu.:0.0000   Class :character   1st Qu.:  0.000  \n Mode  :character   Median :0.0000   Mode  :character   Median :  0.000  \n                    Mean   :0.2523                      Mean   :  4.283  \n                    3rd Qu.:0.0000                      3rd Qu.:  0.000  \n                    Max.   :7.0000                      Max.   :577.000  \n                                                                         \n     atwork            atfaci           attrans            covid     \n Min.   :  0.000   Min.   :  0.000   Min.   : 0.0000   Min.   :0.00  \n 1st Qu.:  0.000   1st Qu.:  0.000   1st Qu.: 0.0000   1st Qu.:0.00  \n Median :  0.000   Median :  0.000   Median : 0.0000   Median :0.00  \n Mean   :  2.757   Mean   :  1.273   Mean   : 0.3064   Mean   :0.25  \n 3rd Qu.:  0.000   3rd Qu.:  0.000   3rd Qu.: 0.0000   3rd Qu.:0.25  \n Max.   :467.000   Max.   :244.000   Max.   :58.0000   Max.   :1.00  \n                                                                     \n     hdibi            inter             hdibi2           inter2       \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.3979   Mean   :0.08756   Mean   :0.1846   Mean   :0.04147  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n NA's   :104                        NA's   :88                        \n     stabi            inter3            lat             long        \n Min.   :0.0000   Min.   :0.0000   Min.   : 0.00   Min.   :  1.167  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:12.42   1st Qu.: 18.375  \n Median :1.0000   Median :0.0000   Median :21.25   Median : 45.000  \n Mean   :0.5369   Mean   :0.1348   Mean   :25.42   Mean   : 56.235  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:40.00   3rd Qu.: 80.000  \n Max.   :1.0000   Max.   :1.0000   Max.   :72.00   Max.   :178.000  \n                                   NA's   :20      NA's   :20       \n      lat2             long2        \n Min.   :-41.000   Min.   :-175.00  \n 1st Qu.:  4.375   1st Qu.: -11.62  \n Median : 17.292   Median :  20.00  \n Mean   : 19.195   Mean   :  19.37  \n 3rd Qu.: 39.625   3rd Qu.:  50.73  \n Max.   : 72.000   Max.   : 178.00  \n NA's   :20        NA's   :20       \n\ncleaned <- total_df\ncleaned <- rename(cleaned, c(HDI_level=hdilev))\ncleaned <- rename(cleaned, c(Number_Attack=attotal))\n\n\n\nlibrary(plotly) \n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\npar(las=1, mar=c(2, 2, 2, 2), cex=.7)\nfig <- plot_ly()%>%\n  add_trace(x = cleaned$gdp, y = cleaned$stability, \n            type = 'scatter', \n            size = cleaned$Number_Attack, color = cleaned$HDI_level,\n            text = ~paste(\"Country:\", cleaned$region, \"<br>Year:\", cleaned$year),\n            mode = 'markers')\nfig <- fig %>% layout(title = 'Analysis of Attacks, Stability, GDP, and HDI level',\n                      xaxis = list(showgrid = FALSE),\n                      yaxis = list(showgrid = FALSE),\n                      showlegend = TRUE)\n\nconfig(fig, scrollZoom = TRUE)%>%layout(plot_bgcolor='white',\n                                        xaxis = list(\n                                          zerolinecolor = 'gray3',\n                                          zerolinewidth = 2,\n                                          gridcolor = 'blue1'),\n                                        yaxis = list(\n                                          zerolinecolor = 'gray3',\n                                          zerolinewidth = 2,\n                                          gridcolor = 'blue1')\n)\n\nWarning: Ignoring 90 observations\n\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\n\n\n\n\nfig\n\nWarning: Ignoring 90 observations\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values."
  },
  {
    "objectID": "assignment9.html",
    "href": "assignment9.html",
    "title": "assignment9",
    "section": "",
    "text": "Time Series in R\n\nlibrary(TSstudio)\n\nWarning: package 'TSstudio' was built under R version 4.0.5\n\nquantmod::getSymbols(\"AAPL\", src=\"yahoo\")\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\n[1] \"AAPL\"\n\nts_plot(AAPL$AAPL.Adjusted, \n        title = \"Apple Stock prices\",\n        Ytitle = \"\")\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'tibble'\n\n\nWarning: replacing previous import 'lifecycle::last_warnings' by\n'rlang::last_warnings' when loading 'pillar'\n\n\n\n\n\nclass(AAPL) # What class is this object?\n\n[1] \"xts\" \"zoo\"\n\n# Some sample dataset from TSstudio\nts_seasonal(USgas, type = \"box\") # month-year matrix data\n\n\n\n\n# What class is USgas?\n\n# Sample charts\nts_heatmap(USgas)\n\n\n\n\nts_cor(USgas) # ACF and PACF\n\n\n\n\nts_lags(USgas, margin = .01)\n\n\n\n\nusgas=data.frame(USgas)\n\n\n# Libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.0.5\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# Load dataset from github\ndata <- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/3_TwoNumOrdered.csv\", header=T)\ndata$date <- as.Date(data$date)\n\n# Usual area chart\np <- data %>%\n  ggplot( aes(x=date, y=value)) +\n    geom_area(fill=\"#69b3a2\", alpha=0.5) +\n    geom_line(color=\"#69b3a2\") +\n    ylab(\"bitcoin price ($)\") +\n    theme_classic()\n\n# Turn it interactive with ggplotly\np <- ggplotly(p)\np"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dohyo Jeong",
    "section": "",
    "text": "I am a Ph.D. candidate studying the Public Policy and Political Economy.\nMy research topic is on Public Health Policy, Machine Learning, Geographic Information Science.\n\nMore Information\n\nInterests:\n* Policy Analysis\n* Public Health Policy\n* Data Science\n* Time series modeling\n* Geographic Information Science\n\nContact me\n\n[email] dohyo91@gmail.com\n[Website] https://dohyojeong.github.io"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "Project\n\n\n3. Identifying Hotspots of Tuberculosis in Nigeria using EWORS: Implications for Active Case Finding and Intervention.\n- Research Assistant, University of Texas at Dallas\n\nCombining and managing Nigerian tuberculosis data\nDisease distribution mapping and pattern analysis\nEWORS system effectiveness analysis and evaluation\nSystem effect mapping and geospatial analysis\n\n\n\n2. Emergency Medical Services (EMS) Policy Implementation Evaluation and Efficiency Analysis in Nigeria\n- Research Assistant, University of Texas at Dallas\n\nNigeria traffic accident information mapping and data management\nAmbulance Reaction Time Patterns and Statistical Analysis\nAnalysis and evaluation of traffic policy effects\n\n\n\n1. Pursuing an Empathic Government Through Convergent Leadership Development Program\n- Research Assistant, SUNGKYUNKWAN UNIVERSITY/NATIONAL RESEARCH FOUNDATION OF KOREA\n 1. Party of support: National Research Foundation of Korea\n\nResponsibilities:\n\n\nDiagnosis and development of problems in interdisciplinary convergence research\n\n\nCompare the concept of ‘Publicity’ in the West and the East, and study the definition of publicity in Korean Public Administration\nCompare the bureaucracy theory of the Oriental administration Philosopher Han Feizi and the bureaucracy theory of Max Weber in the West, and derive various implications for application to modern bureaucracy\n\n\nAnalysis and evaluation of the influence of government trust\nStudy the influence of tax recognition and government trust on the welfare policy attitude\n\n\n\n\n\n\nWork Experience\n\n\n2. Gyeonggi Research Institute, Korea\nResearcher, Economic and Social Research Lab (Jan.2020 - May 2020)\n\nResponsibilities\n\n\nLocal industry geographic distribution data collection and analysis.\nEstablishment and analysis of strategic plans for regional strategic industries.\nIndustry policy evaluation and report.\n\n\n\n1. Sustainable Urban Development Institute (SUDI)\nSungkyunkwan University, Seoul, Korea (Apr. 2019 - Jan. 2020)\nResearcher, the Center for Urban Policy Studies \n\nResponsibilities:\n\n\nDiagnosis of problems of local autonomy and decentralization, and development of improvement measures\nAssessment of local government’s fiscal soundness and efficiency\nPolicy development for sustainable local government and rational creation of finance\nStudy on applicability of flexible taxes, tax competition, evaluation of local fiscal reconciliation system, and allocation of government subsidies\nDatabase city information and utilize that information for city research and policy development data\nResearch and application of statistics package such as STATA, SPSS, AMOS, and SAS"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Publications\n[8] DOHYO JEONG, Jessi Hanson-DeFusco, and Dohyeong Kim. (2022). Digital Mass Hysteria? during Pandemics: A Case Study of Twitter Communication Patterns in the US during COVID-19 Period. Journal of Health Communication. (During peer reviewing).\n[7] DOHYO JEONG, Dohyeong Kim, Heba Mohiuddin, SungYeun Kim. (2022). Regional disparity in the educational impact of COVID-19: a spatial difference-in-difference approach. Journal of Environmental and Public Health. (During peer reviewing).\n[6] Ogbudebe Chidubem, DOHYO JEONG, OdumeBethrand ….. (2022). Editorial Decision/Comments on “Identifying Hotspots of Tuberculosis in Nigeria using Early Warning Outbreak Recognition System: Retrospective Analysis of Implications for Active Case Finding Interventions. JMIR Public Health & Surveillance.\n[5] DOHYO JEONG, Sangho Moon, SUHO BAE. (2019). Factors Affecting the Distribution of National Subsidies in Korean Local Governments: Focusing on Rhodes’ Power-Dependence Model. The Korea Journal of Policy Analysis and Management, Vol.29 No3: 21-53.\n[4] DOHYO JEONG, CHANG-JIN KIM, SUHO BAE. (2019). A Study on Determinants of Tax Attitude: Focusing on Slippery Slope Framework, Public Policy Review, Vol.33 No.3: 43-72.\n[3] CHANG-JIN KIM, DOHYO JEONG, SUNG-WOO HONG. (2019). The Effects of Decentralization Perception on the Recognition of Intergovernmental Relationship: Focusing on Mediating Effect of Dispute Settlement System - Journal of Local Government Studies.Vol.31 No.3: 1-35.\n[2] DOHYO JEONG, YOUNGKYU LEE, SEONGYOUNG JEONG. (2018). An Analysis of the Effect of the Tax Rate on the Financial Efficiency of Local Governments. The Korea Journal of Local Government Studies, Vol.22 No.3: 415-443.\n[1] Dae-yong Hyun, DOHYO JEONG, (2017). Analysis of differences in perception of administrative values among civil servants and general civil servants: Focused on Suwon City Government Officials. Suwon Research Institute. No. 12: 119-141.\n\n\n\n\n\nConference Presentation\n[8] DOHYO JEONG. (2023). Digital Mass Hysteria? during Pandemics: A Case Study of Twitter Communication Patterns in the US during COVID-19 Period. Conference On Public Process Research. 12. Jan. 2023.\n[7] DOHYO JEONG. (2022). A comparison of the spread trend prediction model according to the government’s COVID-19 response policy change and its influence, 2022 Korean Public Administration International Conference. Korea. 22 June. 2022.\n[6] DOHYO JEONG. (2021). The effect of the government’s vaccination management plan on the change of sentiment toward vaccines, 2021 Global Disastronomy Workshop. Texas. USA. 17 Dec. 2021.\n[5] DOHYO JEONG, Chang-jin Kim. SUHO BAE. (2019). A Study on the Factors Affecting the Taxation Attitude of General Taxpayers. Korean Association for Local Government Studies Winter Conference. Seoul. KOREA. 14 Feb. 2019\n[4] Chang-jin Kim. DOHYO JEONG, SUHO BAE. (2019). The Mediation Effect of Dispute Settlement System in the Perception of Regional Dispersion and Intergovernmental Relations. Korean Association for Local Government Studies Winter Conference. Seoul. KOREA. 14 Feb. 2019.\n[3] DOHYO JEONG, YOUNGKYU LEE, SUHO BAE. (2018) An Analysis of the Effect of the Tax Rate on the Financial Efficiency of Local Governments. Korea Association of Local Administration Summer Joint Conference Chungcheong-do. KOREA. 20 Jul. 2018\n[2] DOHYO JEONG. (2017). The Effects of Tax Recognition on the pros and cons of Welfare Policy. Seoul Association of Public Administration Fall Conference. Seoul. KOREA. 3 Nov. 2017\n[1] Dae-yong Hyun, DOHYO JEONG. (2017). A Study on the Policy Diffusion of Local Government in Korea: focusing on Resident Participation Budget System. Korea Association of Local Administration Summer Joint Conference. Gyeonggi-do. KOREA. 18 Aug. 2017"
  }
]